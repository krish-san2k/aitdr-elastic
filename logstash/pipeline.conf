input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["events"]
    codec => json
  }
}

filter {
  # Parse Suricata/Snort IDS/IPS events
  if [source] == "suricata" or [source] == "snort" {
    # Parse Suricata/Snort EVE JSON format
    json {
      source => "message"
      target => "suricata"
    }
    
    # Extract key fields
    mutate {
      add_field => {
        "src_ip" => "%{[suricata][src_ip]}"
        "dest_ip" => "%{[suricata][dest_ip]}"
        "src_port" => "%{[suricata][src_port]}"
        "dest_port" => "%{[suricata][dest_port]}"
        "protocol" => "%{[suricata][proto]}"
        "alert_signature" => "%{[suricata][alert][signature]}"
        "alert_category" => "%{[suricata][alert][category]}"
        "alert_severity" => "%{[suricata][alert][severity]}"
      }
    }
  }
  
  # Normalize common fields from multiple sources
  if [source_ip] and [dest_ip] {
    # IPs already present
    mutate {
      add_field => {
        "src_ip" => "%{source_ip}"
        "dest_ip" => "%{dest_ip}"
      }
    }
  } else if [message] and ![src_ip] {
    # Try to parse IPs from message
    grok {
      match => { "message" => "%{IP:src_ip}.*%{IP:dest_ip}" }
      tag_on_failure => ["_grokparsefailure"]
    }
  }
  
  # Normalize timestamp
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
    }
  } else if [suricata][timestamp] {
    date {
      match => ["[suricata][timestamp]", "ISO8601"]
      target => "@timestamp"
    }
  }
  
  # Add processing metadata
  mutate {
    add_field => {
      "logstash_timestamp" => "%{@timestamp}"
      "processed_by" => "logstash"
      "pipeline_version" => "2.0"
    }
  }
  
  # Set default severity if not present
  if ![severity] and ![alert_severity] {
    if [detector] == "network_ips" or [detector] == "suricata" or [detector] == "snort" {
      mutate { add_field => { "severity" => 5.0 } }
    }
  }
  
  # Enrich with GeoIP data (requires GeoIP database)
  if [src_ip] and [src_ip] != "-" {
    geoip {
      source => "src_ip"
      target => "geoip_src"
    }
  }
  
  if [dest_ip] and [dest_ip] != "-" {
    geoip {
      source => "dest_ip"
      target => "geoip_dest"
    }
  }
  
  # Add risk scoring based on patterns
  if [alert_severity] == 1 {
    mutate { add_field => { "risk_score" => 9.0 } }
  } else if [alert_severity] == 2 {
    mutate { add_field => { "risk_score" => 7.0 } }
  } else if [alert_severity] == 3 {
    mutate { add_field => { "risk_score" => 5.0 } }
  } else if ![risk_score] {
    mutate { add_field => { "risk_score" => 3.0 } }
  }
}

output {
  # Send to Elasticsearch with daily indices
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "raw-logs-%{+YYYY.MM.dd}"
    action => "index"
  }
  
  # Send alerts to separate index
  if [alert_signature] or [severity] > 7 {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "alerts-%{+YYYY.MM.dd}"
      action => "index"
    }
  }
  
  # Debug output
  stdout {
    codec => json_lines
  }
}
